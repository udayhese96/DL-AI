!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/


!kaggle datasets download -d salader/dogs-vs-cats


!unzip dogs-vs-cats.zip


import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout


train_ds = keras.utils.image_dataset_from_directory(
    directory = '/content/dogs_vs_cats/test',
    labels = 'inferred',
    label_mode = 'int',
    batch_size = 32,
    image_size = (256, 256)
)


validation_ds = keras.utils.image_dataset_from_directory(
    directory = '/content/dogs_vs_cats/train',
    labels = 'inferred',
    label_mode = 'int',
    batch_size = 32,
    image_size = (256, 256)
)


import matplotlib.pyplot as plt
import os

# Manually specify the class names based on the directory structure
class_names = sorted(os.listdir('/content/dogs_vs_cats/test'))
print("Class names:", class_names)

# Number of images to display per class
images_per_class = 10

# Set the figure size (adjust this based on the number of classes and images per class)
plt.figure(figsize=(images_per_class * 2, len(class_names) * 2))

# Initialize a dictionary to track how many images have been plotted per class
img_count = {class_name: 0 for class_name in class_names}

# Iterate through the dataset
for images, labels in train_ds:
    for i in range(len(images)):
        label_index = labels[i].numpy()  # Convert label tensor to numpy index
        label_name = class_names[label_index]  # Get class name
        if img_count[label_name] < images_per_class:
            plt.subplot(len(class_names), images_per_class, sum(img_count.values()) + 1)
            plt.imshow(images[i].numpy().astype("uint8"))
            plt.title(label_name)
            plt.axis("off")
            img_count[label_name] += 1
        if all(count >= images_per_class for count in img_count.values()):
            break
    if all(count >= images_per_class for count in img_count.values()):
        break

plt.subplots_adjust(wspace=0.2, hspace=0.2)  # Adjust spacing between images
plt.show()


# Normalize
def process(image, label):
  image = tf.cast(image/255. , tf.float32)
  return image, label

train_ds = train_ds.map(process)
validation_ds = validation_ds.map(process)


# CNN Model

model = Sequential()

model.add(Conv2D(32, kernel_size=(3,3), padding='valid', activation='relu', input_shape=(256,256,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))

model.add(Conv2D(64, kernel_size=(3,3), padding='valid', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))

model.add(Conv2D(128, kernel_size=(3,3), padding='valid', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))

model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1, activation='sigmoid'))


model.summary()


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


history=model.fit(train_ds,epochs=10,validation_data=validation_ds)


plt.plot(history.history['accuracy'], color='red', label='train')
plt.plot(history.history['val_accuracy'], color='blue', label='validation')
plt.legend()
plt.show()


plt.plot(history.history['loss'], color='red', label='train')
plt.plot(history.history['val_loss'], color='blue', label='validation')
plt.legend()
plt.show()


print('Test Accuracy is', model.evaluate(validation_ds)[1]*100, '%')
